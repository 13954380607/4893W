---
title: "4893W"
author: "Dongnan Liu"
date: "2025-03-16"
output:
  pdf_document: default
  html_document: default
---

```{r}
# Install necessary packages (if not already installed)
install.packages(c("tidyverse", "randomForest", "xgboost", "caret", "pROC", "SHAPforxgboost"))

# Load required libraries
library(tidyverse)     # Data manipulation
library(caret)         # Machine learning
library(randomForest)  # Random Forest
library(xgboost)       # XGBoost
library(pROC)          # AUC-ROC analysis
library(SHAPforxgboost) # SHAP interpretation for XGBoost

# Load the dataset
df <- read.csv("C:/Users/DELL/Desktop/diabetes_prediction_dataset.csv")

# üéØ Keep only non-diabetic individuals
df_non_diabetic <- df %>% filter(diabetes == 0)

# üõ†Ô∏è Check for missing values
colSums(is.na(df_non_diabetic))

# üõ†Ô∏è Handle missing values (replace with mean)
df_non_diabetic <- df_non_diabetic %>%
  mutate(across(c(age, bmi, HbA1c_level, blood_glucose_level), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

# üîç Encode categorical variables properly
df_non_diabetic$gender <- as.factor(df_non_diabetic$gender)
df_non_diabetic$smoking_history <- as.factor(df_non_diabetic$smoking_history)
df_non_diabetic$heart_disease <- as.factor(df_non_diabetic$heart_disease)
```
```{r}
X <- df_non_diabetic %>% select(-c(diabetes, heart_disease))
y <- df_non_diabetic$heart_disease
```


```{r}
# üéØ Load necessary libraries
library(caret)
library(randomForest)
library(xgboost)
library(pROC)
library(PRROC)
library(zoo)

# üéØ Split dataset into training and test sets (80-20 split)
set.seed(4052)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# üéØ Compute Class Weights
num_heart_disease <- sum(y_train == 1)
num_no_heart_disease <- sum(y_train == 0)
class_weight_rf <- c(num_no_heart_disease, num_heart_disease) / length(y_train)
xgb_weight <- num_no_heart_disease / num_heart_disease

# üéØ Train Random Forest
rf_model <- randomForest(
  x = X_train, y = y_train, ntree = 1000, importance = TRUE,
  classwt = class_weight_rf
)
rf_pred <- predict(rf_model, X_test, type = "prob")[,2]

# üéØ Prepare data for XGBoost
X_train_matrix <- model.matrix(~. -1, data = X_train)
X_test_matrix <- model.matrix(~. -1, data = X_test)
y_train_numeric <- as.numeric(y_train) - 1
y_test_numeric <- as.numeric(y_test) - 1

xgb_model <- xgboost(
  data = X_train_matrix, label = y_train_numeric, nrounds = 100,
  objective = "binary:logistic", eval_metric = "auc",
  scale_pos_weight = xgb_weight, verbose = 0
)
xgb_pred <- predict(xgb_model, X_test_matrix)

# üéØ Interpolated ROC Curve
thresholds <- seq(0, 1, length.out = 1000)
roc_rf <- roc(y_test_numeric, rf_pred, quiet = TRUE)
roc_xgb <- roc(y_test_numeric, xgb_pred, quiet = TRUE)

roc_rf_interp <- coords(roc_rf, x = thresholds, input = "threshold",
                        ret = c("specificity", "sensitivity"), transpose = FALSE)
roc_xgb_interp <- coords(roc_xgb, x = thresholds, input = "threshold",
                         ret = c("specificity", "sensitivity"), transpose = FALSE)

plot(1 - roc_rf_interp$specificity, roc_rf_interp$sensitivity, type = "l", col = "blue", lwd = 2,
     xlab = "1 - Specificity", ylab = "Sensitivity", main = "Interpolated ROC Curve (Fair Comparison)")
lines(1 - roc_xgb_interp$specificity, roc_xgb_interp$sensitivity, col = "red", lwd = 2)
abline(0, 1, lty = 2, col = "gray")
legend("bottomright", legend = c("Random Forest", "XGBoost"), col = c("blue", "red"), lty = 1)

# üéØ Interpolated AUC
auc_interp <- function(specificity, sensitivity) {
  x <- 1 - specificity
  y <- sensitivity
  idx <- order(x)
  sum(diff(x[idx]) * zoo::rollmean(y[idx], 2))
}
rf_auc_interp <- auc_interp(roc_rf_interp$specificity, roc_rf_interp$sensitivity)
xgb_auc_interp <- auc_interp(roc_xgb_interp$specificity, roc_xgb_interp$sensitivity)

cat("Interpolated AUC - Random Forest:", round(rf_auc_interp, 4), "\n")
cat("Interpolated AUC - XGBoost:", round(xgb_auc_interp, 4), "\n")

# üéØ F1-score with error handling
f1_score <- function(predictions, actual) {
  pred_class <- ifelse(predictions > 0.5, 1, 0)
  cm <- table(factor(actual, levels = c(0,1)), factor(pred_class, levels = c(0,1)))
  TP <- cm[2,2]; FP <- cm[1,2]; FN <- cm[2,1]
  precision <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  recall <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  f1 <- ifelse((precision + recall) == 0, 0, 2 * precision * recall / (precision + recall))
  return(f1)
}
f1_rf <- f1_score(rf_pred, y_test_numeric)
f1_xgb <- f1_score(xgb_pred, y_test_numeric)

cat("Random Forest F1-Score:", round(f1_rf, 4), "\n")
cat("XGBoost F1-Score:", round(f1_xgb, 4), "\n")

# üéØ Confusion Matrices
rf_pred_class <- ifelse(rf_pred > 0.5, 1, 0)
xgb_pred_class <- ifelse(xgb_pred > 0.5, 1, 0)
conf_matrix_rf <- table(Predicted = factor(rf_pred_class, levels = c(0,1)),
                        Actual = factor(y_test_numeric, levels = c(0,1)))
conf_matrix_xgb <- table(Predicted = factor(xgb_pred_class, levels = c(0,1)),
                         Actual = factor(y_test_numeric, levels = c(0,1)))

get_precision_recall <- function(cm) {
  TP <- cm[2,2]; FP <- cm[2,1]; FN <- cm[1,2]
  precision <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  recall <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  return(c(precision = precision, recall = recall))
}

rf_metrics <- get_precision_recall(conf_matrix_rf)
xgb_metrics <- get_precision_recall(conf_matrix_xgb)

print("Confusion Matrix for Random Forest:")
print(conf_matrix_rf)
cat("Random Forest Precision:", round(rf_metrics["precision"], 4), "\n")
cat("Random Forest Recall:", round(rf_metrics["recall"], 4), "\n")

print("Confusion Matrix for XGBoost:")
print(conf_matrix_xgb)
cat("XGBoost Precision:", round(xgb_metrics["precision"], 4), "\n")
cat("XGBoost Recall:", round(xgb_metrics["recall"], 4), "\n")

# üéØ PR-AUC
pr_rf <- pr.curve(scores.class0 = rf_pred[y_test_numeric == 1],
                  scores.class1 = rf_pred[y_test_numeric == 0], curve = TRUE)
pr_xgb <- pr.curve(scores.class0 = xgb_pred[y_test_numeric == 1],
                   scores.class1 = xgb_pred[y_test_numeric == 0], curve = TRUE)

cat("PR AUC - Random Forest:", round(pr_rf$auc.integral, 4), "\n")
cat("PR AUC - XGBoost:", round(pr_xgb$auc.integral, 4), "\n")

# üéØ PR Curve Plot
plot(pr_rf$curve[,1], pr_rf$curve[,2], type = "l", col = "blue", lwd = 2,
     xlab = "Recall", ylab = "Precision", main = "Precision-Recall Curve")
lines(pr_xgb$curve[,1], pr_xgb$curve[,2], col = "red", lwd = 2)
legend("bottomleft", legend = c("Random Forest", "XGBoost"), col = c("blue", "red"), lty = 1)
```

```{r}
# üîÅ Fix the horizontal axis: 1 - specificity, as a common evaluation basis
x_fixed <- seq(0, 1, length.out = 1000)

# üîÅ Apply spline interpolation for sensitivity values of both models onto the same x-axis
y_rf_interp <- approx(1 - roc_rf_interp$specificity, roc_rf_interp$sensitivity, xout = x_fixed)$y
y_xgb_interp <- approx(1 - roc_xgb_interp$specificity, roc_xgb_interp$sensitivity, xout = x_fixed)$y

# üîÅ Now y_rf_interp and y_xgb_interp share the same x-axis
plot(x_fixed, y_rf_interp, type = "l", col = "blue", lwd = 2,
     xlab = "1 - Specificity", ylab = "Sensitivity", main = "Fair ROC Comparison (Spline Interpolated)")
lines(x_fixed, y_xgb_interp, col = "red", lwd = 2)
legend("bottomright", legend = c("Random Forest", "XGBoost"), col = c("blue", "red"), lty = 1)

# üìä Check sensitivity difference after spline interpolation
abs_diff <- abs(y_rf_interp - y_xgb_interp)
mean_abs_diff <- mean(abs_diff)
rel_diff <- mean(abs_diff / ((y_rf_interp + y_xgb_interp) / 2))

cat("Mean absolute difference in sensitivity:", round(mean_abs_diff, 4), "\n")
cat("Mean relative difference in sensitivity:", round(rel_diff, 4), "\n")

# üìà Plot the sensitivity difference curve (XGB - RF)
plot(x_fixed, y_xgb_interp - y_rf_interp, type = "l", col = "purple", lwd = 2,
     xlab = "1 - Specificity", ylab = "Sensitivity Difference (XGB - RF)",
     main = "Sensitivity Difference Across 1 - Specificity")
abline(h = 0, lty = 2, col = "gray")
```

```{r}
roc.test(roc_rf, roc_xgb, method = "delong")
plot(pr_rf$curve[,1], pr_rf$curve[,2], type = "l", col = "blue", lwd = 2,
     xlab = "Recall", ylab = "Precision", main = "Precision-Recall Curve")
lines(pr_xgb$curve[,1], pr_xgb$curve[,2], col = "red", lwd = 2)
legend("bottomleft", legend = c("Random Forest", "XGBoost"), col = c("blue", "red"), lty = 1)
print(paste("PR AUC - Random Forest:", round(pr_rf$auc.integral, 4)))
print(paste("PR AUC - XGBoost:", round(pr_xgb$auc.integral, 4)))
```

```{r}
install.packages("PRROC")
```
```{r}
library(PRROC)

pr_rf <- pr.curve(scores.class0 = rf_pred, weights.class0 = y_test_numeric, curve = TRUE)
pr_xgb <- pr.curve(scores.class0 = xgb_pred, weights.class0 = y_test_numeric, curve = TRUE)

print(paste("Random Forest PR-AUC:", round(pr_rf$auc.integral, 4)))
print(paste("XGBoost PR-AUC:", round(pr_xgb$auc.integral, 4)))

# üéØ 3Ô∏è‚É£ Statistical Test for AUC Comparison Between RF & XGBoost
roc_test <- roc.test(roc_rf, roc_xgb)  # Performs DeLong‚Äôs test for two correlated ROC curves
print(roc_test)

# üéØ 4Ô∏è‚É£ Adjust XGBoost Decision Threshold to Improve F1-Score
thresholds <- seq(0.3, 0.7, by = 0.05)
best_f1 <- 0
best_threshold <- 0.5

for (t in thresholds) {
  pred_adjusted <- ifelse(xgb_pred > t, 1, 0)
  f1_adj <- f1_score(pred_adjusted, y_test_numeric)
  if (f1_adj > best_f1) {
    best_f1 <- f1_adj
    best_threshold <- t
  }
}

print(paste("Best XGBoost Threshold:", best_threshold))
print(paste("Improved XGBoost F1-Score:", round(best_f1, 4)))
```
```{r}
library(ggplot2)
library(reshape2)

# Convert confusion matrix to data frame
plot_conf_matrix <- function(conf_matrix, model_name) {
  conf_matrix_df <- as.data.frame(as.table(conf_matrix))
  colnames(conf_matrix_df) <- c("Predicted", "Actual", "Freq")
  
  ggplot(conf_matrix_df, aes(x = Actual, y = Predicted, fill = Freq)) +
    geom_tile() +
    geom_text(aes(label = Freq), color = "white", size = 6) +
    scale_fill_gradient(low = "blue", high = "red") +
    labs(title = paste("Confusion Matrix for", model_name), x = "Actual", y = "Predicted") +
    theme_minimal()
}

# Plot for RF and XGBoost
plot_conf_matrix(conf_matrix_rf, "Random Forest")
plot_conf_matrix(conf_matrix_xgb, "XGBoost")
```
```{r}
# üéØ SHAP Feature Importance for XGBoost
library(SHAPforxgboost)

# Prepare SHAP values
shap_values <- shap.prep(xgb_model = xgb_model, X_train = X_train_matrix)

# Plot SHAP Summary
shap.plot.summary(shap_values)
```
```{r}
# Load necessary libraries
library(caret)
library(ranger)
library(doParallel)

# Define hyperparameter grid
rf_grid <- expand.grid(
  mtry = c(2, 4, 6),               # Number of variables randomly sampled at each split
  splitrule = c("gini"),           # Use Gini impurity
  min.node.size = c(1, 3, 5)       # Minimum node size
)

# Define cross-validation control
control <- trainControl(method = "cv", number = 3, search = "grid")

# Enable parallel processing
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Train Random Forest model with hyperparameter tuning
rf_optimized <- train(
  heart_disease ~ ., data = df_non_diabetic,
  method = "ranger",
  trControl = control,
  tuneGrid = rf_grid
)

stopCluster(cl)  # Stop parallel processing

# Print best hyperparameters
print("Best Hyperparameters for Random Forest:")
print(rf_optimized$bestTune)

```


```{r}
install.packages("ggcorrplot")
```

```{r}
# Load necessary library
library(ggcorrplot)

X_train_numeric <- X_train[, sapply(X_train, is.numeric)]
cor_matrix <- cor(X_train_numeric)


# Plot Correlation Heatmap
ggcorrplot(cor_matrix, method = "circle", lab = TRUE, title = "Feature Correlation Heatmap")
```
